{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb5c1c8",
   "metadata": {},
   "source": [
    "### Guide on langchain agents. Available agents and custom agent creation\n",
    "\n",
    "#### This notebook provides the content on pre-build agents availables from langchain module and the functionality to build custom agent\n",
    "      \n",
    "#### Link for all available agents with langchain. Refer to toolkit section in documentation: https://python.langchain.com/v0.1/docs/integrations/toolkits/\n",
    "\n",
    "#### Link to langchain custom agent generation. Go through all subsecgtions under agent. Refer to section tool callings.: https://python.langchain.com/v0.1/docs/modules/agents/\n",
    "\n",
    "#### Links to short course on Agentic AI: https://learn.deeplearning.ai/courses/functions-tools-agents-langchain/lesson/1/introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d17f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chintan_patel\\AppData\\Local\\Temp\\ipykernel_20520\\2853668691.py:16: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(api_key=openai_key)\n"
     ]
    }
   ],
   "source": [
    "### Initiate LLM object using langchain. Have separate guide.\n",
    "# from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "# from langchain_openai import AzureOpenAIEmbeddings\n",
    "# from langchain_community.chat_models import AzureChatOpenAI\n",
    "\n",
    "## Create embedding of the chunks using Faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Required following parameters. Update following input parameters. Make sure embedding model and LLM models are deployed within same resource.\n",
    "openai_key=\"<Enter OpenAI Key Here>\"\n",
    "llm = ChatOpenAI(api_key=openai_key,model=\"gpt-4o-mini\")\n",
    "\n",
    "embedding = OpenAIEmbeddings(api_key=openai_key)\n",
    "\n",
    "\n",
    "# llm = AzureChatOpenAI(azure_deployment=api_deployment,\n",
    "#                       api_version=api_version,\n",
    "#                       azure_endpoint=base_url,\n",
    "#                       api_key=api_key,\n",
    "#                       model=model_name)\n",
    "\n",
    "\n",
    "# embedding = AzureOpenAIEmbeddings(deployment=embedding_deployment,\n",
    "#                                         openai_api_key=api_key,\n",
    "#                                         openai_api_version=api_version,\n",
    "#                                         azure_endpoint=base_url,\n",
    "#                                         openai_api_type=\"azure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c8055",
   "metadata": {},
   "source": [
    "### CSV Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd2ad97",
   "metadata": {},
   "source": [
    "##### Agent which takes python dataframe as input with user prompt. It generates and exectues the python code using python_repl_ast tool. \n",
    "##### Refer to details documentations: https://python.langchain.com/v0.1/docs/integrations/toolkits/csv/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442cf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf4052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class csv_agent_res:\n",
    "    \n",
    "    def __init__(self,query,llm,kpi_df):\n",
    "        '''\n",
    "        Initiate csv agent class.\n",
    "        query: User Prompt\n",
    "        llm: Langchain llm object\n",
    "        kpi_df: Dataframe to query.\n",
    "        '''\n",
    "        self.query=query\n",
    "        self.llm=llm\n",
    "        self.kpi_df=kpi_df\n",
    "        self.kpi_df_head = kpi_df.head()  \n",
    "        self.prefix=\"\"\"\n",
    "                        You are working with python dataframe. The name of dataframe is `df`.\n",
    "                        Do not create your own dataframe.\n",
    "                        Do not create your own question.\n",
    "\n",
    "                        You should use the 'python_repl_ast' tool to answer the question posed of you and Use the format given below:\n",
    "                            Question: Input question you must answer. Do not create your own question and dataframe. Use provided df and question to answer.\n",
    "                            Thought: You should always think about what to do and what action to take. Do not repeat the same thought.\n",
    "                            Action: python_repl_ast\n",
    "                            Action Input: Input to the action, never add backticks \"`\" arround the action\n",
    "                            Observation: The result of the action. Memorize the Obersavation for each thought. Do not repeat the same thought.\n",
    "                            ...(Different Thought/Action/Action Input/Observation can repeat N times step by step and stop once you get the Final Answer.)\n",
    "                            Thought: I know the Final Answer. Generate Final Answer. Stop when you know Final Answer and generate Final Answer.\n",
    "                            Final Answer: The final answer to the original input question\n",
    "            \"\"\"\n",
    "        self.suffix=\"\"\"\n",
    "                    This is result of `print(df.head())` to understand columns content:\n",
    "                    {df_head}\n",
    "                    \n",
    "                    Customer column is customer or company who signed the contract with the legal entity.\n",
    "                    \n",
    "                    Begin!\n",
    "                    Question: {input}\n",
    "                    {agent_scratchpad}\n",
    "                    \"\"\"\n",
    "        \n",
    "        \n",
    "        self.cost_details={}\n",
    "        self.cost_details['prompt_tokens']=0\n",
    "        self.cost_details['completion_tokens']=0\n",
    "        self.cost_details['api_calls']=0\n",
    "        self.cost_details['llm_cost']=0\n",
    "        \n",
    "    def csv_response(self):\n",
    "        \n",
    "        '''\n",
    "        Generate response using the csv agent.\n",
    "        '''\n",
    "        \n",
    "        try:\n",
    "            #Initialize the agent\n",
    "            self.pd_agent = create_pandas_dataframe_agent(llm=self.llm,\n",
    "                                                            df=self.kpi_df,\n",
    "                                                            suffix=self.suffix,\n",
    "                                                            prefix=self.prefix,\n",
    "                                                            include_df_in_prompt=None,\n",
    "                                                            verbose=True,\n",
    "                                                            max_iterations=5,\n",
    "                                                            reduce_k_below_max_tokens=True, \n",
    "                                                            number_of_head_rows=2,\n",
    "                                                            allow_dangerous_code=True,                                   \n",
    "                                                            agent_executor_kwargs={'handle_parsing_errors':True,'Input':self.query}\n",
    "                                                            )\n",
    "            ## Generate cost details\n",
    "            with get_openai_callback() as cb:\n",
    "                self.csv_agent_response=self.pd_agent.run(self.query)\n",
    "                self.cost_details['prompt_tokens']=self.cost_details['prompt_tokens']+cb.prompt_tokens\n",
    "                self.cost_details['completion_tokens']=self.cost_details['completion_tokens']+cb.completion_tokens\n",
    "                self.cost_details['api_calls']=self.cost_details['api_calls']+cb.successful_requests\n",
    "            return self.csv_agent_response,self.cost_details\n",
    "        except Exception as e:\n",
    "            print(\"Exception while generating csv_response >>> \", str(e))\n",
    "            return \"\",self.cost_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5871a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"titanic.csv\")\n",
    "# user_prompt=\"How many memebers are survived ?\"\n",
    "user_prompt=\"How many memebers are survived who were travelling using class 1 tickets?\"\n",
    "user_prompt=\"How many females are survived who were travelling through the class 1 tickets?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00b6f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_agent = csv_agent_res(user_prompt,llm,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a630b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chintan_patel\\.conda\\envs\\genai_hack_2\\lib\\site-packages\\langchain_experimental\\agents\\agent_toolkits\\pandas\\base.py:283: UserWarning: Received additional kwargs {'reduce_k_below_max_tokens': True} which are no longer supported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find out how many females survived while traveling in class 1, I need to filter the dataframe for females who survived and were in Pclass 1, then count the resulting entries. \n",
      "Action: python_repl_ast\n",
      "Action Input: df[(df['Sex'] == 'female') & (df['Survived'] == 1) & (df['Pclass'] == 1)].shape[0]\u001b[0m\u001b[36;1m\u001b[1;3m91\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 91\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = csv_agent.csv_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8240262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('91',\n",
       " {'prompt_tokens': 0, 'completion_tokens': 0, 'api_calls': 0, 'llm_cost': 0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f039fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eed03d87",
   "metadata": {},
   "source": [
    "## Custom Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb618a9",
   "metadata": {},
   "source": [
    "#### Build the custom agent which generally provie flexibility to use custom tools for execution.\n",
    "#### Notebook demonstrate the custom agent which basically retrieve the information from the vector database and calculate using maths tools. Make sure Index folder created during the Step 2 Execution is present else recreate vector embeddings using faiss and store to index folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70edf093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import  tool\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.chains import LLMMathChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "227d1fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db=FAISS.load_local(\"./Index\",embedding)    \n",
    "except:\n",
    "    db=FAISS.load_local(\"./Index\",embedding,allow_dangerous_deserialization=True)\n",
    "    \n",
    "user_query=\"What is total liability of assests as of december 2023 and september 2023.\"\n",
    "\n",
    "#Retrieve the most similar content to pass for simple QA tool.\n",
    "most_similar_chunks = db.similarity_search_with_score(user_query,k=10)\n",
    "aggregated_content = \"\\n\".join([chunk[0].page_content for chunk in most_similar_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc8eba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are multiple ways to add prompt (i.e. system prompt or chat history) while calling the LLMs using langchain. \n",
    "# Here provided most commonally used process.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "#Create the Tools which runs using the custom agent. This notebook will create 2 tools.\n",
    "# 1. Tool 1 : Which generates summary to answer the user question.\n",
    "# 2. Tool 2 : Which execute the the expressions of maths using the LLMMathChain. \n",
    "\n",
    "#Objective here is to make calculation more robust. It has been observed LLM makes mistakes in calculations. Calculations can be done usign LLMMathChain which develop executable expressions for maths.\n",
    "\n",
    "\n",
    "##Doc string can be used as prompt for the TOOL selection.\n",
    "\n",
    "@tool\n",
    "def extract_information(query: str):\n",
    "    \"\"\"\n",
    "    1. Use this tool to retrieve information in term of the mathamatical expressions to answer the user question.\n",
    "    2. Refer to the example of question for this tool selection:\n",
    "      i.e. 1. What is sum of revenue for year 2023 and 2024 for Tibco company?\n",
    "           2. What is total liability for the 2024 and 2020?\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Add custom prompt which produce response as maths expressions. Provide retrieved content here.\n",
    "    \n",
    "    template = ChatPromptTemplate([\n",
    "        (\"system\", \"\"\"\n",
    "                    You are assistant to financial firm. \n",
    "                    Generate the mathamatical expression to answer to the question based on provided content. \n",
    "                    Make sure mathamatical expressions are capable to response user question.\n",
    "                    \n",
    "                    Response sample: Sum the number 2000 and 3000. \n",
    "                    \"\"\"),\n",
    "         (\"human\", \"Questoin: {question} \\n Contenet: :{content}\")])\n",
    "\n",
    "    # All variables must added to while invoking the prompt \n",
    "    prompt_value = template.invoke({\"question\": query,\"content\":aggregated_content})\n",
    "    messages = prompt_value.to_messages()\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "@tool\n",
    "def maths_chain(query: str):\n",
    "    \"\"\"\n",
    "    1. Use this tool to answer question which has mathamatical expressions.\n",
    "    2. Do not use this tool to retrieve the information.\n",
    "    2. Refer to examples:\n",
    "       1. Sum the 30000 and 4000.\n",
    "       2. Multiply the 300 by 200.\n",
    "    \"\"\"\n",
    "    llm_math = LLMMathChain.from_llm(llm)\n",
    "    response = llm_math.invoke(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd106f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_agent_PREFIX = \"\"\"Answer the following questions as best as you can. Do not modify the original question and use it as it is mentioned. You have access to the following tools. You must Select atleast one tool out of two tools mentioned below to generate response for question:\"\"\"\n",
    "\n",
    "outer_agent_FORMAT_INSTRUCTIONS = \"\"\"\n",
    "Do not validate the response generated with one tool with the other tool.\n",
    "Do not use other tool if the tool which is intially selected is not able to generate response. If you are not able to find answer, then respond the final observation.\n",
    "\n",
    "Use the following format strickly:\n",
    "    Question: Input question you must answer. Do not create your own question. Use provided question to answer.\n",
    "    Thought: You should always think about what to do and what action to take. Do not repeat the same thought. Memorize the Obersavation for each thought. Do not repeat the same thought.\n",
    "    Action: The action to take, should be one of [{tool_names}]. Strickly select one of the tool.\n",
    "    Action Input: Input to the action, never add backticks \"`\" arround the action. Do not select any tool which is not in list [{tool_names}]. \n",
    "    Observation: The result of the action. Memorize the Obersavation for each thought. Do not repeat the same thought.\n",
    "    ...(Different Thought/Action/Action Input/Observation can repeat N times step by step and stop once you get the Final Answer.)\n",
    "    Thought: I know the Final Answer. Generate Final Answer. Stop when you know Final Answer and generate Final Answer. You must stop execution once final answer is generated.\n",
    "    Final Answer: Response the final answer to the original input question.\n",
    "\"\"\"\n",
    "                    \n",
    "                                                            \n",
    "outer_agent_SUFFIX = \"\"\"\n",
    "    Begin!\n",
    "\n",
    "    Question: {input}\n",
    "    Thought:{agent_scratchpad}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa3aec30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chintan_patel\\AppData\\Local\\Temp\\ipykernel_20520\\2788978417.py:4: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  agent = initialize_agent(tools,\n"
     ]
    }
   ],
   "source": [
    "tools = load_tools([])\n",
    "tools = tools + [extract_information,maths_chain]\n",
    "\n",
    "agent = initialize_agent(tools,\n",
    "                        llm,\n",
    "                        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                        verbose=True,\n",
    "                        max_iterations=5,\n",
    "                        handle_parsing_errors=True,\n",
    "                        agent_kwargs={'prefix':outer_agent_PREFIX,\n",
    "                                    'format_instructions':outer_agent_FORMAT_INSTRUCTIONS,\n",
    "                                    'suffix':outer_agent_SUFFIX,\n",
    "                                    \"handle_parsing_errors\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87437073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is total liability of assests as of december 2023 and september 2023.\n",
      "Thought: I need to find the total liability of assets for two specific dates, December 2023 and September 2023. This requires retrieving the respective values for those dates.\n",
      "Action: extract_information\n",
      "Action Input: What is total liability of assets as of December 2023 and September 2023?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTotal liability for December 2023 and September 2023 can be expressed as:\n",
      "\n",
      "Total Liabilities = Liabilities (December 31, 2023) + Liabilities (September 30, 2023)\n",
      "\n",
      "Thus, \n",
      "\n",
      "Total Liabilities = 20,755 + 25,890\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI can now calculate the total liabilities using the values obtained from the previous observation. \n",
      "\n",
      "Action: maths_chain  \n",
      "Action Input: Sum the 20755 and 25890.  \u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{'question': 'Sum the 20755 and 25890.', 'answer': 'Answer: 46645'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI know the Final Answer. Generate Final Answer. Stop when you know Final Answer and generate Final Answer. You must stop execution once final answer is generated.  \n",
      "Final Answer: 46645\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = agent.invoke(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "739ac8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is total liability of assests as of december 2023 and september 2023.',\n",
       " 'output': '46645'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f516aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Work Arround: Update the Prompt wiht more reliable few shots. There is no limitation to add new tools to the agent. It also supports nested agent work flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975adb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
